{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, '..')\n",
    "from lib import models, graph, coarsening, utils\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "import scipy.spatial.distance\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# Graphs.\n",
    "flags.DEFINE_integer('number_edges', 1, 'Graph: minimum number of edges per vertex.')\n",
    "flags.DEFINE_string('metric', 'euclidean', 'Graph: similarity measure (between features).')\n",
    "# TODO: change cgcnn for combinatorial Laplacians.\n",
    "flags.DEFINE_bool('normalized_laplacian', True, 'Graph Laplacian: normalized.')\n",
    "flags.DEFINE_integer('coarsening_levels', 1, 'Number of coarsened graphs.')\n",
    "flags.DEFINE_string('dir_data', os.path.join('..', 'data', 'mnist'), 'Directory to store data.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For PPI and PPI-singleton model change file location\n",
    "\n",
    "\n",
    "test = sio.loadmat('GCN_Cancer_Paper/Adj_Filtered_List_0Con.mat')\n",
    "test['Adj_List'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Co-expression network\n",
    "\n",
    "\n",
    "test = sio.loadmat('GCN_Cancer_Paper/Adj_Spearman_6P.mat')\n",
    "\n",
    "test['Adj_Spearman_6P'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, basically is: rows and columns is like a double list of the links, so every link goes from row[a] to col[a], so they represent the pairs of nodes, linked by a link\n",
    "Value is all 1, and its the value of the link.\n",
    "\n",
    "They have all the same dimension, the number of links in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7091 genes used. He uses only 7091 genes, after preprocessing and selecting relevant ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row = test['row'].astype(np.float32)\n",
    "col = test['col'].astype(np.float32)\n",
    "value = test['value'].astype(np.float32)\n",
    "M, k = row.shape\n",
    "row = np.array(row)\n",
    "row = row.reshape(k)\n",
    "row = row.ravel()\n",
    "col = np.array(col)\n",
    "col = col.reshape(k)\n",
    "col = col.ravel()\n",
    "value = np.array(value)\n",
    "value = value.reshape(k)\n",
    "value = value.ravel()\n",
    "A = scipy.sparse.coo_matrix((value, (row, col)),shape = (3866,3866)) # change size for model being used 4444 for both PPI and 3866 for\n",
    "graphs, perm = coarsening.coarsen(A, levels=FLAGS.coarsening_levels, self_connections=True)\n",
    "L = [graph.laplacian(A, normalized=True,renormalized=True) for A in graphs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The co-expression matrix, has only 3886 (due to solitary genes) and PPI has 4444 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row = test['row'].astype(np.float32)\n",
    "col = test['col'].astype(np.float32)\n",
    "value = test['value'].astype(np.float32)\n",
    "M, k = row.shape\n",
    "row = np.array(row)\n",
    "row = row.reshape(k)\n",
    "row = row.ravel()\n",
    "col = np.array(col)\n",
    "col = col.reshape(k)\n",
    "col = col.ravel()\n",
    "value = np.array(value)\n",
    "value = value.reshape(k)\n",
    "value = value.ravel()\n",
    "A = scipy.sparse.coo_matrix((value, (row, col)),shape = (4444,4444)) # change size for model being used 4444 for both PPI and 3866 for\n",
    "graphs, perm = coarsening.coarsen(A, levels=FLAGS.coarsening_levels, self_connections=True)\n",
    "L = [graph.laplacian(A, normalized=True,renormalized=True) for A in graphs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_links = np.any(row == col)\n",
    "self_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data = sio.loadmat('C:/Users/RJ/Desktop/exp_fpkm_pancan/processed/Final/Data/Block_PPIA.mat')\n",
    "Data = sio.loadmat('GCN_Cancer_Paper/Block_PPIA.mat')\n",
    "# Data = sio.loadmat('GCN_Cancer_Paper/Block_6P.mat')\n",
    "\n",
    "\n",
    "Data1 = Data['Block'][0,0]\n",
    "Data2 = Data['Block'][0,1]\n",
    "Data3 = Data['Block'][0,2]\n",
    "Data4 = Data['Block'][0,3]\n",
    "Data5 = Data['Block'][0,4]\n",
    "D1= Data1['D'].astype(np.float32)\n",
    "D2= Data2['D'].astype(np.float32)\n",
    "D3= Data3['D'].astype(np.float32)\n",
    "D4= Data4['D'].astype(np.float32)\n",
    "D5= Data5['D'].astype(np.float32)\n",
    "L1= Data1['L'].astype(np.float32)\n",
    "L2= Data2['L'].astype(np.float32)\n",
    "L3= Data3['L'].astype(np.float32)\n",
    "L4= Data4['L'].astype(np.float32)\n",
    "L5= Data5['L'].astype(np.float32)\n",
    "# adjust for K-Fold cross validation\n",
    "Train_Data = np.transpose(np.hstack((D1,D2,D3,D4)))\n",
    "Val_Data = np.transpose(D5)\n",
    "Test_Data = np.transpose(D5)\n",
    "Train_Label = (np.vstack((L1,L2,L3,L4)))\n",
    "Val_Label = (L5)\n",
    "Test_Label = (L5)\n",
    "Test_Label = Test_Label.ravel()\n",
    "Train_Label = Train_Label.ravel()\n",
    "Val_Label = Val_Label.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Train_Data.shape)\n",
    "print(Test_Data.shape)\n",
    "print(Val_Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Train_Label.shape)\n",
    "print(Test_Label.shape)\n",
    "print(Val_Label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, this is only all the samples with the expression profile of the selected genes (the ones in the graph) as rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it applies this perm_data, that for some reason (?) i adds some extra columns, to match the input layer of the NN. This value is from the coarsing, so should be automatic!!! not fucking sure xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data = coarsening.perm_data(Train_Data, perm)\n",
    "Val_Data = coarsening.perm_data(Val_Data, perm)\n",
    "Test_Data = coarsening.perm_data(Test_Data, perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Train_Data.shape)\n",
    "print(Test_Data.shape)\n",
    "print(Val_Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 34  # number of classes\n",
    "\n",
    "common = {}\n",
    "common['dir_name']       = 'PPI/'\n",
    "common['num_epochs']     = 20\n",
    "common['batch_size']     = 200\n",
    "common['decay_steps']    = 17.7 # * common['num_epochs'] since not used use as in momentum \n",
    "common['eval_frequency'] = 10 * common['num_epochs']\n",
    "common['brelu']          = 'b1relu'\n",
    "common['pool']           = 'apool1'\n",
    "\n",
    "model_perf = utils.model_perf()\n",
    "\n",
    "common['regularization'] = 0\n",
    "common['dropout']        = 1\n",
    "common['learning_rate']  = .005\n",
    "common['decay_rate']     = 0.95\n",
    "common['momentum']       = 0\n",
    "\n",
    "common['F']              = [1]\n",
    "common['K']              = [1]\n",
    "common['p']              = [2]\n",
    "common['M']              = [1024,C]\n",
    "\n",
    "\n",
    "name = 'Run1'\n",
    "params = common.copy()\n",
    "params['dir_name'] += name\n",
    "#    params['filter'] = 'chebyshev5'\n",
    "params['filter'] = 'chebyshev2'\n",
    "params['brelu'] = 'b1relu'\n",
    "model_perf.test(models.cgcnn(L, **params), name, params, Train_Data, Train_Label, Val_Data, Val_Label, Test_Data, Test_Label)\n",
    "\n",
    "model_perf.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
