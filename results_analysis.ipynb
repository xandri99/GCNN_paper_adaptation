{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mat_file(file_path, key):\n",
    "    # Load the MATLAB file\n",
    "    data = scipy.io.loadmat(file_path)\n",
    "    # Assuming the labels or predictions are stored under the key 'labels'\n",
    "    return data[key].squeeze()\n",
    "\n",
    "def compute_metrics(true_labels, predicted_labels):\n",
    "    # Calculate different metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predicted_labels):\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    \n",
    "    # Normalize the confusion matrix by the number of instances in each class (rows)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(cm_normalized, cmap=plt.cm.Blues)\n",
    "    \n",
    "    # Add title and labels\n",
    "    plt.title('Confusion Matrix (% Correct per Class)')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_xticks(np.arange(len(np.unique(true_labels))))\n",
    "    ax.set_yticks(np.arange(len(np.unique(true_labels))))\n",
    "    ax.set_xticklabels(np.unique(true_labels))\n",
    "    ax.set_yticklabels(np.unique(true_labels))\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    # Add numbers to each cell\n",
    "    for (i, j), val in np.ndenumerate(cm_normalized):\n",
    "        ax.text(j, i, f\"{val:.2%}\", ha='center', va='center', color='black')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move out of the notebook folder to access datasets\n",
    "working_dir = os.getcwd()\n",
    "data_dir = working_dir + \"/results/TumorSiteClassification/\"\n",
    "\n",
    "# Load results\n",
    "true_labels = load_mat_file(data_dir + \"Confusion_Val_Lab.mat\", \"labels\")\n",
    "predictions = load_mat_file(data_dir + \"Confusion_Val.mat\", \"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute classification metrics\n",
    "accuracy, precision, recall, f1 = compute_metrics(true_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(true_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knock Up and Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the inference results\n",
    "kup = load_mat_file(data_dir + \"Knockup.mat\", \"Knockup\")\n",
    "kdown = load_mat_file(data_dir + \"Knockdown.mat\", \"Knockdown\")\n",
    "\n",
    "# Adjust dimension\n",
    "kup = kup.T\n",
    "kdown = kdown.T\n",
    "\n",
    "# Load list of genes used\n",
    "selected_genes_df = pd.read_csv(data_dir + 'selected_genes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sample_changes(predictions, modifications):\n",
    "    # Changes matrix: 1 if changed, 0 if not\n",
    "    changes = modifications != predictions[:, None]\n",
    "    # Sum changes for each gene\n",
    "    return np.sum(changes, axis=0)\n",
    "\n",
    "\n",
    "changes_kup = find_sample_changes(predictions, kup)\n",
    "changes_kdown = find_sample_changes(predictions, kdown)\n",
    "\n",
    "gene_effects_df = pd.DataFrame({\n",
    "    'Affected_samples_kup': changes_kup,\n",
    "    'Affected_samples_kdown': changes_kdown\n",
    "}, index=selected_genes_df['Gene Name'])\n",
    "\n",
    "# Sum kup and kdown changes to get total effect per gene\n",
    "gene_effects_df['Total_affected_samples'] = gene_effects_df['Affected_samples_kup'] + gene_effects_df['Affected_samples_kdown']\n",
    "\n",
    "# Sort the DataFrame by Total_affected_samples\n",
    "gene_effects_df = gene_effects_df.sort_values(by='Total_affected_samples', ascending=False).reset_index()\n",
    "\n",
    "# Remove genes with no effect\n",
    "gene_effects_df = gene_effects_df[gene_effects_df['Total_affected_samples'] != 0]\n",
    "\n",
    "\n",
    "print(gene_effects_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset of genes with more consensus\n",
    "modules = gene_effects_df[gene_effects_df['Total_affected_samples'] > 50]\n",
    "\n",
    "\n",
    "# Create a histogram of Total_affected_samples\n",
    "plt.hist(modules['Total_affected_samples'], bins=100, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Total Affected Samples')\n",
    "plt.ylabel(f'Samples (total {modules.shape[0]})')\n",
    "plt.title('Histogram of Total Affected Samples')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()\n",
    "working_dir = working_dir.strip('GCNN_paper_adaptation')\n",
    "data_dir = working_dir + 'Thesis/data/PROTECTED_DATA/BGI_Expression_Data/'\n",
    "\n",
    "\n",
    "## Load the datasets\n",
    "# Transcriptomics Data \n",
    "transcriptomics_TumorOnly_dir = data_dir + 'CRC.SW.mRNA.symbol.TPM_TumorOnly.csv'\n",
    "transcriptomics_dataset = pd.read_csv(transcriptomics_TumorOnly_dir, index_col=0)\n",
    "\n",
    "# Classification Tags\n",
    "labels_classification_dir = data_dir + 'TumourSite_for_TumorSamples_Classification.csv'\n",
    "labels = pd.read_csv(labels_classification_dir, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apostro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
