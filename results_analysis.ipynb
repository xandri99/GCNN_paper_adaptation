{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move out of the notebook folder to access datasets\n",
    "working_dir = os.getcwd()\n",
    "data_dir = working_dir + \"/results/Gender/\"\n",
    "\n",
    "titleee = \"Gender\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mat_file(file_path, key):\n",
    "    # Load the MATLAB file\n",
    "    data = scipy.io.loadmat(file_path)\n",
    "    # Assuming the labels or predictions are stored under the key 'labels'\n",
    "    return data[key].squeeze()\n",
    "\n",
    "def compute_metrics(true_labels, predicted_labels):\n",
    "    # Calculate different metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predicted_labels, title = ''):\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    \n",
    "    # Normalize the confusion matrix by the number of instances in each class (rows)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(cm_normalized, cmap=plt.cm.Blues)\n",
    "    \n",
    "    # Add title and labels\n",
    "    plt.title(title + 'Confusion Matrix', fontsize = 15)\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_xticks(np.arange(len(np.unique(true_labels))))\n",
    "    ax.set_yticks(np.arange(len(np.unique(true_labels))))\n",
    "    ax.set_xticklabels(np.unique(true_labels))\n",
    "    ax.set_yticklabels(np.unique(true_labels))\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    # Add numbers to each cell\n",
    "    for (i, j), val in np.ndenumerate(cm_normalized):\n",
    "        ax.text(j, i, f\"{val:.2%}\", ha='center', va='center', color='black')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "true_labels = load_mat_file(data_dir + \"Confusion_Val_Lab.mat\", \"labels\")\n",
    "predictions = load_mat_file(data_dir + \"Confusion_Val.mat\", \"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute classification metrics\n",
    "accuracy, precision, recall, f1 = compute_metrics(true_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(true_labels, predictions, title = titleee + ' Classification ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knock Up and Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the inference results\n",
    "kup = load_mat_file(data_dir + \"Knockup.mat\", \"Knockup\")\n",
    "kdown = load_mat_file(data_dir + \"Knockdown.mat\", \"Knockdown\")\n",
    "\n",
    "# Adjust dimension\n",
    "kup = kup.T\n",
    "kdown = kdown.T\n",
    "\n",
    "# Load list of genes used\n",
    "selected_genes_df = pd.read_csv(data_dir + 'selected_genes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sample_changes(predictions, modifications):\n",
    "    # Changes matrix: 1 if changed, 0 if not\n",
    "    changes = modifications != predictions[:, None]\n",
    "    # Sum changes for each gene\n",
    "    return np.sum(changes, axis=0)\n",
    "\n",
    "\n",
    "changes_kup = find_sample_changes(predictions, kup)\n",
    "changes_kdown = find_sample_changes(predictions, kdown)\n",
    "\n",
    "gene_effects_df = pd.DataFrame({\n",
    "    'Affected_samples_kup': changes_kup,\n",
    "    'Affected_samples_kdown': changes_kdown\n",
    "}, index=selected_genes_df['Gene Name'])\n",
    "\n",
    "# Sum kup and kdown changes to get total effect per gene\n",
    "gene_effects_df['Total_affected_samples'] = gene_effects_df['Affected_samples_kup'] + gene_effects_df['Affected_samples_kdown']\n",
    "\n",
    "# Sort the DataFrame by Total_affected_samples\n",
    "gene_effects_df = gene_effects_df.sort_values(by='Total_affected_samples', ascending=False).reset_index()\n",
    "\n",
    "# Remove genes with no effect\n",
    "gene_effects_df = gene_effects_df[gene_effects_df['Total_affected_samples'] != 0]\n",
    "\n",
    "\n",
    "print(gene_effects_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset of genes with more consensus\n",
    "modules = gene_effects_df[gene_effects_df['Total_affected_samples'] > 25]\n",
    "\n",
    "\n",
    "# Create a histogram of Total_affected_samples\n",
    "plt.hist(modules['Total_affected_samples'], bins=100, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Total Affected Samples')\n",
    "plt.ylabel(f'Samples (total {modules.shape[0]})')\n",
    "plt.title('Histogram of Total Affected Samples')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()\n",
    "working_dir = working_dir.strip('GCNN_paper_adaptation')\n",
    "data_dir = working_dir + 'Thesis/data/PROTECTED_DATA/BGI_Expression_Data/'\n",
    "\n",
    "\n",
    "## Load the datasets\n",
    "# Transcriptomics Data \n",
    "transcriptomics_TumorOnly_dir = data_dir + 'CRC.SW.mRNA.symbol.TPM_TumorOnly.csv'\n",
    "transcriptomics_dataset = pd.read_csv(transcriptomics_TumorOnly_dir, index_col=0)\n",
    "\n",
    "# Classification Tags\n",
    "labels_classification_dir = data_dir + 'TumourSite_for_TumorSamples_Classification.csv'\n",
    "labels = pd.read_csv(labels_classification_dir, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = modules[['Gene Name', 'Total_affected_samples']]\n",
    "transcriptomics_dataset_transposed = transcriptomics_dataset.transpose()\n",
    "transcriptomics_dataset_transposed.reset_index(inplace=True)\n",
    "transcriptomics_dataset_transposed.rename(columns={'index': 'Gene Name'}, inplace=True)\n",
    "expression_profile = pd.merge(modules, transcriptomics_dataset_transposed, on='Gene Name', how='inner')\n",
    "expression_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the modules to csv for comparative analysis.\n",
    "working_dir = os.getcwd()\n",
    "results_dir = working_dir + '/results/ComparativeAnalysis/'\n",
    "\n",
    "# Check if the directory exists, and if not, create it\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    print(f\"Creating directory to save results and figures...\")\n",
    "\n",
    "\n",
    "expression_profile.to_csv(results_dir + 'GenderModulesExP_GCNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_data = expression_profile.drop(columns=['Total_affected_samples'])\n",
    "expression_data.set_index('Gene Name', inplace=True)\n",
    "expression_data_np = expression_data.values\n",
    "correlation_matrix = np.corrcoef(expression_data_np, rowvar=True)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Eigengene\n",
    "\n",
    "# Perform PCA on the expression data of the current module\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(expression_data)\n",
    "\n",
    "# The first principal component is the eigengene\n",
    "eigengene = pca.components_[0]\n",
    "\n",
    "eigengene.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color mapping for different intervals of correlation strengths\n",
    "interval_colors = {\n",
    "    '0.9 - 1.0': 'red',\n",
    "    '0.8 - 0.9': 'orange',\n",
    "    '0.7 - 0.8': 'yellow',\n",
    "    '0.6 - 0.7': 'blue',\n",
    "    \n",
    "    '0.0 - 0.5': 'green',\n",
    "    }\n",
    "\n",
    "# Function to determine color based on weight\n",
    "def get_edge_color(weight, interval_colors):\n",
    "    for interval, color in interval_colors.items():\n",
    "        lower, upper = map(float, interval.split(' - '))\n",
    "        if lower <= abs(weight) <= upper:\n",
    "            return color\n",
    "    return 'grey'\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "# Build full expression profile\n",
    "new_row = pd.DataFrame([eigengene], columns=expression_data.columns, index=['EigenGene'])\n",
    "module_profile = pd.concat([expression_data, new_row])\n",
    "\n",
    "# Convert to numpy and calculate Spearman correlation -> Membership function in a way\n",
    "module_profile_matrix = module_profile.to_numpy()\n",
    "corr, _ = spearmanr(module_profile_matrix, axis=1)\n",
    "corr_matrix = pd.DataFrame(corr, index=module_profile.index, columns=module_profile.index)\n",
    "\n",
    "# Network creation and node addition\n",
    "G = nx.Graph()\n",
    "for gene in module_profile.index:\n",
    "    G.add_node(gene)\n",
    "\n",
    "# Edge addition based on correlation\n",
    "for gene1 in module_profile.index:\n",
    "    for gene2 in module_profile.index:\n",
    "        if gene1 != gene2:\n",
    "            weight = corr_matrix.loc[gene1, gene2]\n",
    "            if abs(weight) >= 0.0:\n",
    "                color = get_edge_color(weight, interval_colors)\n",
    "                G.add_edge(gene1, gene2, weight=weight, color=color)\n",
    "\n",
    "# Plotting the network in a subplot\n",
    "pos = nx.spring_layout(G, k=0.5, iterations=20)\n",
    "edges = G.edges(data=True)\n",
    "nx.draw(G, pos, with_labels=True, node_color=['red' if name=='EigenGene' else 'skyblue' for name in G.nodes], \n",
    "        node_size=500, \n",
    "        edge_color=[data['color'] for _, _, data in edges], linewidths=1, font_size=10,\n",
    "        width=[(data['weight'])*2 for _, _, data in edges])\n",
    "\n",
    "plt.title(f'Module for {titleee} classification')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Add a legend for the whole figure\n",
    "legend_labels = {label: plt.Line2D([0], [0], color=color, lw=4) for label, color in interval_colors.items()}\n",
    "plt.figlegend(legend_labels.values(), legend_labels.keys(), loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\"\"\"\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apostro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
